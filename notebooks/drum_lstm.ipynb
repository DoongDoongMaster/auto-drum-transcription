{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 18:12:42.107536: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-10 18:12:42.170480: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-10 18:12:42.458320: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-10 18:12:42.458365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-10 18:12:42.460604: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-10 18:12:42.645788: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-10 18:12:42.649096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 18:12:44.199346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hyunlee103.tistory.com/36\n",
    "\n",
    "# # 데이터 전처리 함수\n",
    "# def preprocess_data(wav_file_path, labels):\n",
    "#     # WAV 파일을 스펙트로그램으로 변환하고 필요한 전처리 수행\n",
    "#     # ...\n",
    "\n",
    "#     # 라벨링된 데이터를 이진 벡터와 시작 시간으로 분리\n",
    "#     binary_vectors = labels[:, :8]\n",
    "#     start_times = labels[:, 8]\n",
    "#     return spectrogram_data, binary_vectors, start_times\n",
    "\n",
    "max_pad_len = 174\n",
    "def extract_feature(file_name):\n",
    "    print('file name :', file_name)\n",
    "    try:\n",
    "        # res_type='kaiser_fast' : resampy 더 빠른 방법\n",
    "        # 여부에 따라 값이 다르게 나오긴 함\n",
    "        # resampy\n",
    "        # 다차원 리샘플링을 지원하며 오디오 애플리케이션에 매우 적합합니다.\n",
    "        # 장기간 신호(예: 고품질 샘플링 속도에서 몇 분)의 경우 resampy는 scipy.signal.resample 보다\n",
    "        # 상당히 빠르며 오디오 품질에서는 인지할 수 있는 차이가 거의 없습니다.\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0,0), (0, pad_width)), mode='constant')\n",
    "        print(mfccs.shape)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01000000\t000\n",
      "\n",
      "01000000\t100\n",
      "\n",
      "01000000\t200\n",
      "\n",
      "01000000\t300\n",
      "\n",
      "01000000\t000\n",
      "\n",
      "01000000\t050\n",
      "\n",
      "01000000\t100\n",
      "\n",
      "01000000\t150\n",
      "\n",
      "01000000\t200\n",
      "\n",
      "01000000\t250\n",
      "\n",
      "01000000\t300\n",
      "\n",
      "01000000\t350\n",
      "\n",
      "01000000\t000\n",
      "\n",
      "01000000\t025\n",
      "\n",
      "01000000\t050\n",
      "\n",
      "01000000\t075\n",
      "\n",
      "01000000\t100\n",
      "\n",
      "01000000\t125\n",
      "\n",
      "01000000\t150\n",
      "\n",
      "01000000\t175\n",
      "\n",
      "01000000\t200\n",
      "\n",
      "01000000\t225\n",
      "\n",
      "01000000\t250\n",
      "\n",
      "01000000\t275\n",
      "\n",
      "01000000\t300\n",
      "\n",
      "01000000\t325\n",
      "\n",
      "01000000\t350\n",
      "\n",
      "01000000\t375\n",
      "\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../data/wavs/record/per_drum/1_HH/label.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/wotjr/Documents/Github/drum-classification/src/drum_lstm.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/wotjr/Documents/Github/drum-classification/src/drum_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m rhythm \u001b[39min\u001b[39;00m rhythm_folder:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/wotjr/Documents/Github/drum-classification/src/drum_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     rhythm_folder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(element_folder_path, rhythm)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/wotjr/Documents/Github/drum-classification/src/drum_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(rhythm_folder_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/wotjr/Documents/Github/drum-classification/src/drum_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     wav_files \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(rhythm_folder_path, file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.m4a\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/wotjr/Documents/Github/drum-classification/src/drum_lstm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     txt_files \u001b[39m=\u001b[39m [file \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../data/wavs/record/per_drum/1_HH/label.txt'"
     ]
    }
   ],
   "source": [
    "# label-data mapping 해서 저장\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# label class {HH: 0, RC: 1, ST: 0, ..., rhythm: 0}\n",
    "\n",
    "# 드럼 녹음 data path\n",
    "root_path = \"../data/wavs/record/\"\n",
    "\n",
    "# [pattern, per_drum]\n",
    "drum_folders = os.listdir(root_path)\n",
    "for drum_folder in drum_folders:\n",
    "    drum_folder_path = os.path.join(root_path, drum_folder)\n",
    "    element_folder = os.listdir(drum_folder_path)\n",
    "    # pattern : [1_HH, 2_RC, ...], per_drum : [P1, P2, ...]\n",
    "    for element in element_folder:\n",
    "            element_folder_path = os.path.join(drum_folder_path, element)\n",
    "            rhythm_folder = os.listdir(element_folder_path)\n",
    "            # 04, 08, 16\n",
    "            for rhythm in rhythm_folder:\n",
    "                rhythm_folder_path = os.path.join(element_folder_path, rhythm)\n",
    "                files = os.listdir(rhythm_folder_path)\n",
    "                wav_files = [os.path.join(rhythm_folder_path, file) for file in files if file.endswith('.m4a')]\n",
    "                txt_files = [file for file in files if file.endswith('.txt')]\n",
    "                if len(txt_files) > 0:\n",
    "                    f = open(os.path.join(rhythm_folder_path, txt_files[0]), 'r')\n",
    "                    # 라벨링 값 가져오기\n",
    "                    # 01000000\t000\n",
    "                    # 01000000\t100\n",
    "                    while True:\n",
    "                        line = f.readline()\n",
    "                        if not line: break\n",
    "                        print(line)\n",
    "                    f.close()\n",
    "\n",
    "                # outputs = txt_files\n",
    "                # print(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for  wav_list:\n",
    "\n",
    "# wav_files = [os.path.join(root_path, file) for file in wav_list if file.endswith('.wav')]\n",
    "# print(wav_list)\n",
    "\n",
    "# # for CC, HH, RC... folder open\n",
    "# #   for 04, 08, 16 folder open\n",
    "# #       get wav from mp4 files\n",
    "# #       get label from label.txt\n",
    "\n",
    "# # data는 우리가 리브로사로 추출한 mfccs라는 특성이고\n",
    "# # class_label은 그 음향의 종류를 나타낸다.\n",
    "\n",
    "# features = []\n",
    "# for wav_file in wav_files:\n",
    "#     data = extract_feature(wav_file)\n",
    "#     class_label = 0\n",
    "#     if 'Overhead' in wav_file:\n",
    "#         class_label = 1\n",
    "#     elif 'Snare' in wav_file:\n",
    "#         class_label = 2\n",
    "#     elif 'Tom' in wav_file:\n",
    "#         class_label = 3\n",
    "#     elif 'Bass' in wav_file:\n",
    "#         class_label = 4\n",
    "#     else:\n",
    "#         class_label = 0\n",
    "#     features.append([data, class_label])\n",
    "\n",
    "# # Convert into a Panda dataframe \n",
    "# featuresdf = pd.DataFrame(features, columns=['feature','class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 및 전처리\n",
    "root = \"../data/wavs/test/\"\n",
    "test = root + \"Overhead Sample 30.wav\"\n",
    "\n",
    "\n",
    "\n",
    "wav_file_path = \"path_to_your_wav_file.wav\"\n",
    "labels = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0],  # 예시 라벨링 데이터\n",
    "                   [0, 0, 0, 0, 1, 0, 0, 0, 100]])  # 예시 라벨링 데이터\n",
    "input_data, binary_vectors, start_times = preprocess_data(wav_file_path, labels)\n",
    "\n",
    "# 모델 입력의 형태 설정\n",
    "input_shape = input_data.shape[1:]\n",
    "\n",
    "# 이진 벡터 예측 레이어\n",
    "binary_vector_output = Dense(8, activation='sigmoid', name='binary_vector')(x)\n",
    "\n",
    "# 시작 시간 예측 레이어\n",
    "start_time_output = Dense(1, name='start_time')(x)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=input_layer, outputs=[binary_vector_output, start_time_output])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss={'binary_vector': 'binary_crossentropy', 'start_time': 'mean_squared_error'})\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(input_data, {'binary_vector': binary_vectors, 'start_time': start_times}, epochs=100, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
