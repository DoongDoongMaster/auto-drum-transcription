{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 20:45:12.138820: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-16 20:45:12.140296: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-16 20:45:12.171468: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-16 20:45:12.172789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-16 20:45:12.722094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    print('file name :', file_name)\n",
    "    try:\n",
    "        # res_type='kaiser_fast' : resampy 더 빠른 방법\n",
    "        # 여부에 따라 값이 다르게 나오긴 함\n",
    "        # resampy\n",
    "        # 다차원 리샘플링을 지원하며 오디오 애플리케이션에 매우 적합합니다.\n",
    "        # 장기간 신호(예: 고품질 샘플링 속도에서 몇 분)의 경우 resampy는 scipy.signal.resample 보다\n",
    "        # 상당히 빠르며 오디오 품질에서는 인지할 수 있는 차이가 거의 없습니다.\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        # audio, sample_rate = librosa.load(file_name)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0,0), (0, pad_width)), mode='constant')\n",
    "        print(mfccs.shape)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "#     return padded_mfccs\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "file name : ../data/wavs/train/Overhead Sample 1.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 10.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 11.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 12.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 13.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 14.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 15.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 16.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 17.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 18.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 19.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 2.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 20.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 21.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 22.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 23.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 24.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 25.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 26.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 27.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 28.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 29.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 3.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 30.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 31.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 32.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 33.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 34.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 35.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 36.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 37.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 38.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 39.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 4.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 40.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 5.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 6.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 7.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 8.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Overhead Sample 9.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 1.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 10.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 11.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 12.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 13.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 14.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 15.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 16.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 17.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 18.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 19.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 2.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 20.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 21.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 22.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 23.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 24.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 25.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 26.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 27.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 28.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 29.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 3.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 30.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 31.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 32.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 33.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 34.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 35.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 36.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 37.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 38.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 39.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 4.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 40.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 5.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 6.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 7.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 8.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Snare Sample 9.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 1.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 10.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 11.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 12.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 13.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 14.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 15.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 16.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 17.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 18.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 19.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 2.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 20.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 21.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 22.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 23.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 24.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 25.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 26.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 27.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 28.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 29.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 3.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 30.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 31.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 32.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 33.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 34.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 35.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 36.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 37.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 38.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 39.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 4.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 40.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 5.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 6.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 7.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 8.wav\n",
      "(40, 174)\n",
      "file name : ../data/wavs/train/Tom Sample 9.wav\n",
      "(40, 174)\n"
     ]
    }
   ],
   "source": [
    "# training dataset\n",
    "root_path = \"../data/wavs/train/\"\n",
    "wav_list = os.listdir(root_path)\n",
    "wav_files = [os.path.join(root_path, file) for file in wav_list if file.endswith('.wav')]\n",
    "print(len(wav_files))\n",
    "\n",
    "# data는 우리가 리브로사로 추출한 mfccs라는 특성이고\n",
    "# class_label은 그 음향의 종류를 나타낸다.\n",
    "\n",
    "features = []\n",
    "for wav_file in wav_files:\n",
    "    data = extract_feature(wav_file)\n",
    "    class_label = 0\n",
    "    if 'Overhead' in wav_file:\n",
    "        class_label = 1\n",
    "    elif 'Snare' in wav_file:\n",
    "        class_label = 2\n",
    "    elif 'Tom' in wav_file:\n",
    "        class_label = 3\n",
    "    else:\n",
    "        class_label = 0\n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 불러온 featuresdf에서 feature는 X에 저장하였고 class_label은 y로 저장하였다.\n",
    "# 헌데 y는 yy로 변환과정을 거쳐서 다시 저장되었다.\n",
    "# 둘의 차이는 원-핫-인코딩의 여부이다.\n",
    "# 원-핫-인코딩은 1,2,3 있을 때 1: [1.0.0] / 2:[0.1.0] / 3:[0.0.1] 로 변환해주는 거임.\n",
    "# 이렇게 변환해서 사용하는 이유는 우리가 작성할 딥러닝 모델이 멀티 클래스(3~ 가지) 분류를 하기 때문이다.\n",
    "\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train >>  (96, 40, 174)\n",
      "x_test >>  (24, 40, 174)\n",
      "y >>  [1 1 1 1 1 1 1 1 1 1]\n",
      "yy >>  [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_test >>  [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "\n",
    "print(\"x_train >> \", x_train.shape)\n",
    "print(\"x_test >> \", x_test.shape)\n",
    "print(\"y >> \", y[:10])\n",
    "print(\"yy >> \", yy[:10])\n",
    "print(\"y_test >> \", y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "\n",
    "def pca_scale(x):\n",
    "    print(x.shape)\n",
    "    scaled = scaler.transform(x)\n",
    "    # scaled_x = pca.transform(scaled)\n",
    "    \n",
    "    # return scaled_x\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 40, 174)\n",
      "(222720, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [222720, 96]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# x_train = pca.fit_transform(scaled)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# x_train = pca_scale(scaled)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     x_train = tf.reshape(x_train, [-1, n_row, n_columns, n_channels])\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     x_test = tf.reshape(x_test, [-1, n_row, n_columns, n_channels])\u001b[39;00m\n\u001b[1;32m     25\u001b[0m knr\u001b[38;5;241m=\u001b[39mKNeighborsRegressor(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mknr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m결정 계수 >> \u001b[39m\u001b[38;5;124m\"\u001b[39m, knr\u001b[38;5;241m.\u001b[39mscore(x_train, y_train))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# # importing module\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# from sklearn.linear_model import LinearRegression\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# # creating an object of LinearRegression class\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# LR = LinearRegression()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# # fitting the training data\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# LR.fit(x_train,y_train)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_regression.py:218\u001b[0m, in \u001b[0;36mKNeighborsRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# KNeighborsRegressor.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors regressor from the training dataset.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors regressor.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:456\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 456\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [222720, 96]"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import CategoricalNB\n",
    "# clf = CategoricalNB(force_alpha=True)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "n_columns = 174    \n",
    "n_row = 40       \n",
    "n_channels = 1\n",
    "n_classes = 3\n",
    "\n",
    "# print(x_train[0][0])\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(-1, 3)\n",
    "print(x_train.shape)\n",
    "scaled = scaler.fit_transform(x_train)\n",
    "# x_train = pca.fit_transform(scaled)\n",
    "# x_train = pca_scale(scaled)\n",
    "\n",
    "# # input shape 조정\n",
    "# # cpu를 사용해서 수행한다\n",
    "# with tf.device('/cpu:0'):\n",
    "#     x_train = tf.reshape(x_train, [-1, n_row, n_columns, n_channels])\n",
    "#     x_test = tf.reshape(x_test, [-1, n_row, n_columns, n_channels])\n",
    "\n",
    "\n",
    "knr=KNeighborsRegressor(n_neighbors=2)\n",
    "knr.fit(x_train, y_train)\n",
    "print(\"결정 계수 >> \", knr.score(x_train, y_train))\n",
    "\n",
    "# # importing module\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# # creating an object of LinearRegression class\n",
    "# LR = LinearRegression()\n",
    "# # fitting the training data\n",
    "# LR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/wavs/test/\"\n",
    "test = root + \"Overhead Sample 30.wav\"\n",
    "# test = root + \"Snare Sample 30.wav\"\n",
    "# test = root + \"Tom Sample 30.wav\"\n",
    "\n",
    "# input shape 조정\n",
    "# cpu를 사용해서 수행한다\n",
    "\n",
    "n_columns = 174    \n",
    "n_row = 40       \n",
    "n_channels = 1\n",
    "\n",
    "# input shape 조정\n",
    "# cpu를 사용해서 수행한다\n",
    "input = np.array(extract_feature(test))\n",
    "# with tf.device('/cpu:0'):\n",
    "#     input = tf.reshape(input, [-1, n_row, n_columns, n_channels])\n",
    "print(input)\n",
    "input = np.array([input]).reshape(-1, 2)\n",
    "\n",
    "input = pca_scale(input)\n",
    "print(input)\n",
    "\n",
    "# input = pca_scale(input)\n",
    "\n",
    "# 예측\n",
    "prediction = knr.predict(input)\n",
    "print(\"prediction>>>\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
